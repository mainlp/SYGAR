{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create OpenAI Image Batch Files for Few-Shot Abstract Visual Reasoning Task\n",
    "This script creates prompts related to the few-shot experiment. We use `GPT-4o` via the OpenAI API to evaluate the model on the abstract visual reasoning task. We create a batch files that contain chunks of the test set with images. The input is the same as given to the meta-learning model, but displayed as an image, with an additional prompt that instructs the model with the respective task. The output should be the predicted output grid. Three few-shot examples are given for the task in this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Image Batch File\n",
    "We exploit OpenAI's Batch API to make efficient use of their model and reduce API costs. For this, we first need to create a batch file that contains all the prompts we want to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-2024-08-06\"\n",
    "\n",
    "SEED = 1860\n",
    "DATA_DIR = f\"data/split_seed_{SEED}_only_few_shots\"\n",
    "FILE_NAME = f\"systematicity_seed_{SEED}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = f\"{MODEL}/image_batch_files/split_seed_{SEED}_only_few_shots\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"### Task Description:\n",
    "You must solve an abstract visual reasoning task by identifying geometric transformations (e.g., rotation, translation, color changes, etc.) applied to objects within a 10x10 grid.\n",
    "\n",
    "To infer the correct geometric transformation, you are given a series of **3 pairs of input-output examples**. Each example pair consists of:\n",
    "- An **input grid**: a 10x10 list of lists (2d array), where each element is an integer (0-9).\n",
    "- A corresponding **output grid**: a 10x10 list of lists (2d array) that has undergone a transformation based on a specific geometric rule.\n",
    "\n",
    "For the prediction you need to understand the transformations displayed in the provided examples and apply them to the final input grid.\n",
    "\n",
    "#### Your Task:\n",
    "1. **Analyze** the example pairs to infer the transformation rules applied to each input grid.\n",
    "2. **Identify** how these transformations are applied to generate the output grids.\n",
    "3. **Apply** the deduced transformations to the final input grid.\n",
    "4. **Output** the correctly transformed 10x10 grid.\n",
    "\n",
    "### Output Requirements:\n",
    "- **Return only the final output grid.**\n",
    "- Do not include any extra text, explanations, or comments.\n",
    "- Do not generate any code to solve the task.\n",
    "- The output must be formatted exactly as:\n",
    " `output: [[...]]`\n",
    "- The output grid must be a 10x10 list of lists containing only integers between 0 and 9 (inclusive).\n",
    "- Do not include unnecessary line breaks or additional text beyond the specified format.\n",
    "\n",
    "### Input Format:\n",
    "You will receive the following data:\n",
    "1. **Study examples:** A list of 3 few-shot example pairs, formatted as:\n",
    "  `example input 1: [[...]], example output 1: [[...]], ..., example input 3: [[...]], example output 3: [[...]]`\n",
    "2. **Final input:** A single 10x10 list of lists on which you must apply the inferred transformation(s).\n",
    "3. **Image input:** Addtionally, you receive an image that visualizes the 3 few-shot example pairs and the final input query.\n",
    "\n",
    "Your goal is to determine the correct transformation and return the final output grid.\n",
    "\n",
    "### Input:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vmlc.utils.utils import load_jsonl\n",
    "\n",
    "test_data = load_jsonl(\n",
    "    file_path=f\"{DATA_DIR}/test_{FILE_NAME}.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "def encode_image(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Encodes an image file to a base64 string.\n",
    "\n",
    "    This function reads the image from the specified path in binary mode,\n",
    "    encodes the image data to base64, and returns the resulting string.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The file path to the image to be encoded.\n",
    "\n",
    "    Returns:\n",
    "        str: The base64-encoded string representation of the image.\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        \n",
    "def decode_image(base64_string: str, output_image_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Decodes a base64 string into an image file.\n",
    "\n",
    "    This function decodes the provided base64-encoded string back into binary data\n",
    "    and writes the resulting data to the specified output file path.\n",
    "\n",
    "    Args:\n",
    "        base64_string (str): The base64-encoded string of the image.\n",
    "        output_image_path (str): The file path where the decoded image will be saved.\n",
    "    \"\"\"\n",
    "    image_data = base64.b64decode(base64_string)\n",
    "    with open(output_image_path, \"wb\") as output_file:\n",
    "        output_file.write(image_data)\n",
    "\n",
    "def encode_figure(figure: Figure, fmt: str = \"png\") -> str:\n",
    "    \"\"\"\n",
    "    Encodes a matplotlib figure as a base64 string without writing it to disk.\n",
    "    \n",
    "    The function saves the provided figure into an in-memory buffer in the specified format,\n",
    "    encodes the resulting image data into a base64 string, and returns that string.\n",
    "    \n",
    "    Args:\n",
    "        figure (Figure): The matplotlib figure to encode.\n",
    "        fmt (str, optional): The file format for the encoded image (e.g., 'png', 'jpeg').\n",
    "                             Defaults to \"png\".\n",
    "    \n",
    "    Returns:\n",
    "        str: A base64-encoded string representing the image of the figure.\n",
    "    \"\"\"\n",
    "    # Create an in-memory bytes buffer\n",
    "    buffer = io.BytesIO()\n",
    "    \n",
    "    # Save the figure to the buffer\n",
    "    figure.savefig(buffer, format=fmt, bbox_inches=\"tight\")\n",
    "    \n",
    "    # Ensure the buffer's pointer is at the beginning of the stream\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    # Read the buffer's content and encode it to base64\n",
    "    encoded_image = base64.b64encode(buffer.read()).decode(\"utf-8\")\n",
    "    \n",
    "    # Clean up the buffer\n",
    "    buffer.close()\n",
    "    \n",
    "    return encoded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "def get_custom_cmap() -> mcolors.ListedColormap:\n",
    "    \"\"\"\n",
    "    Returns a ListedColormap using a specified color order.\n",
    "\n",
    "    Returns:\n",
    "        mcolors.ListedColormap: The custom colormap.\n",
    "    \"\"\"\n",
    "    colors = [\n",
    "        \"black\",   # Background (value 0)\n",
    "        \"red\",     # value 1\n",
    "        \"orange\",  # value 2\n",
    "        \"yellow\",  # value 3\n",
    "        \"green\",   # value 4\n",
    "        \"blue\",    # value 5\n",
    "        \"purple\",  # value 6\n",
    "        \"pink\",    # value 7\n",
    "        \"cyan\",    # value 8\n",
    "        \"grey\",    # value 9\n",
    "        \"white\"    # Extra if needed\n",
    "    ]\n",
    "    return mcolors.ListedColormap(colors)\n",
    "\n",
    "def plot_grid(ax: plt.Axes, grid: Any, title: str, cmap: mcolors.Colormap,\n",
    "              vmin: int = 0, vmax: int = 10) -> None:\n",
    "    \"\"\"\n",
    "    Plots a grid on the given axes with a title.\n",
    "\n",
    "    Args:\n",
    "        ax (plt.Axes): Axes on which to plot.\n",
    "        grid (Any): Grid data (convertible to a NumPy array).\n",
    "        title (str): Title for the subplot.\n",
    "        cmap (mcolors.Colormap): Colormap to use.\n",
    "        vmin (int, optional): Minimum data value. Defaults to 0.\n",
    "        vmax (int, optional): Maximum data value. Defaults to 10.\n",
    "    \"\"\"\n",
    "    grid_array = np.array(grid)\n",
    "    rows, cols = grid_array.shape\n",
    "    ax.imshow(grid_array, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(title, fontsize=9)\n",
    "    ax.set_xticks(np.arange(cols + 1) - 0.5, minor=True)\n",
    "    ax.set_yticks(np.arange(rows + 1) - 0.5, minor=True)\n",
    "    ax.grid(True, which=\"minor\", color=\"white\", linewidth=0.5)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "def add_arrow(ax: plt.Axes) -> None:\n",
    "    \"\"\"\n",
    "    Adds an arrow annotation to the axes and hides the axis.\n",
    "\n",
    "    Args:\n",
    "        ax (plt.Axes): Axes on which to add the arrow.\n",
    "    \"\"\"\n",
    "    ax.annotate(\n",
    "        \"\",\n",
    "        xy=(1.4, 0.5),\n",
    "        xytext=(-0.8, 0.5),\n",
    "        arrowprops=dict(arrowstyle=\"->\", lw=1),\n",
    "        xycoords=\"axes fraction\",\n",
    "        textcoords=\"axes fraction\"\n",
    "    )\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "def extract_grid_pairs(study_examples: List[Any]) -> List[Tuple[Any, Any]]:\n",
    "    \"\"\"\n",
    "    Extracts input/output grid pairs from the nested 'study_examples' structure.\n",
    "    \n",
    "    Assumes each study example is nested as: example[0] is a list containing\n",
    "    at least two grids (input and output).\n",
    "\n",
    "    Args:\n",
    "        study_examples (List[Any]): The nested study_examples data.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[Any, Any]]: A list of (input_grid, output_grid) pairs.\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    for input_output_pair in study_examples:\n",
    "        pairs.append((input_output_pair[0], input_output_pair[1]))\n",
    "    return pairs\n",
    "\n",
    "def extract_query_input(queries: List[Any]) -> Any:\n",
    "    \"\"\"\n",
    "    Extracts the input grid for the query from the nested 'queries' structure.\n",
    "    \n",
    "    Assumes queries are nested as: queries[0][0][0] is the query input grid.\n",
    "\n",
    "    Args:\n",
    "        queries (List[Any]): The nested queries data.\n",
    "\n",
    "    Returns:\n",
    "        Any: The query input grid.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the query grid is not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return queries[0][0]\n",
    "    except (IndexError, TypeError):\n",
    "        raise ValueError(\"Query input grid not found in the provided data.\")\n",
    "\n",
    "def plot_study_examples(test_episode: Dict[str, Any], verbose: int = 0) -> str:\n",
    "    \"\"\"\n",
    "    Plots a series of input/output grid pairs from study_examples and a query input\n",
    "    from queries, then returns the plot as a base64-encoded image.\n",
    "\n",
    "    Args:\n",
    "        test_episode (Dict[str, Any]): Data containing keys 'study_examples' and 'queries'.\n",
    "\n",
    "    Returns:\n",
    "        str: Base64-encoded image string of the resulting plot.\n",
    "    \"\"\"\n",
    "    cmap = get_custom_cmap()\n",
    "\n",
    "    # Extract grid pairs from the study_examples field\n",
    "    study_examples = test_episode.get(\"study_examples\", [])\n",
    "    grids = extract_grid_pairs(study_examples)\n",
    "    num_examples = len(grids)\n",
    "\n",
    "    # Extract the query input grid from queries\n",
    "    queries = test_episode.get(\"queries\", [])\n",
    "    query_input = extract_query_input(queries)\n",
    "\n",
    "    # Create figure: one row per grid pair plus one extra row for the query; 3 columns layout\n",
    "    fig, axes = plt.subplots(num_examples + 1, 3,\n",
    "                             figsize=(7.68, 2 * (num_examples + 2)),\n",
    "                             gridspec_kw={'width_ratios': [1, 0.1, 1]})\n",
    "    fig.suptitle(\"Study Examples\", fontsize=12, fontweight=\"bold\", x=0.02, ha=\"left\", y=0.82)\n",
    "    plt.subplots_adjust(top=0.78, hspace=0.3)\n",
    "\n",
    "    # Plot each study example (input/output pair)\n",
    "    for i in range(num_examples):\n",
    "        plot_grid(axes[i, 0], grids[i][0], f\"Example input {i+1}:\", cmap)\n",
    "        add_arrow(axes[i, 1])\n",
    "        plot_grid(axes[i, 2], grids[i][1], f\"Example output {i+1}:\", cmap)\n",
    "\n",
    "    # Plot query input on the last row (only the input grid)\n",
    "    query_ax = axes[num_examples, 0]\n",
    "    pos = query_ax.get_position()\n",
    "    new_y0 = pos.y0 - 0.01\n",
    "    new_y1 = pos.y1 - 0.01\n",
    "    query_ax.set_position([pos.x0, new_y0, pos.width, new_y1 - new_y0])\n",
    "    plt.text(0, new_y1 + 0.01, \"Query\", fontsize=12, fontweight=\"bold\",\n",
    "             ha=\"left\", transform=fig.transFigure)\n",
    "    plot_grid(query_ax, query_input, \"Final input:\", cmap)\n",
    "    add_arrow(axes[num_examples, 1])\n",
    "    axes[num_examples, 2].axis(\"off\")\n",
    "\n",
    "    # Optional: print image size info\n",
    "    fig_width, fig_height = fig.get_size_inches()\n",
    "    dpi = fig.dpi\n",
    "\n",
    "    if verbose > 0:\n",
    "        print(f\"Image size: {int(fig_width * dpi)}x{int(fig_height * dpi)} pixels\")\n",
    "        plt.show()\n",
    "        \n",
    "    encoded_image = encode_figure(fig)\n",
    "    plt.close(fig)\n",
    "    return encoded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_example = plot_study_examples(test_data[1], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Dict, Optional\n",
    "\n",
    "from vmlc.utils.utils import save_dicts_as_jsonl\n",
    "\n",
    "def prepare_study_examples(study_examples: List[List[List[List[str]]]]) -> str:\n",
    "    study_example_str = \"\"\n",
    "\n",
    "    for idx, input_output_pair in enumerate(study_examples):\n",
    "        assert len(input_output_pair) == 2, f\"Invalid number of input and output grids! {len(input_output_pair)}\"\n",
    "        input_grid = f\"\\nexample input {idx + 1}: {input_output_pair[0]}\"\n",
    "        output_grid = f\"\\nexample output {idx + 1}: {input_output_pair[1]}\"\n",
    "\n",
    "        study_example_str += input_grid + output_grid\n",
    "    \n",
    "    return study_example_str\n",
    "\n",
    "\n",
    "def prepare_batch_files(\n",
    "    test_data: List[Dict[str, Any]],\n",
    "    user_prompt: str,\n",
    "    num_samples_per_batch_file: int,\n",
    "    model: str,\n",
    "    out_dir: str,\n",
    "    few_shot_examples: Optional[List[str]] = None\n",
    ") -> None:\n",
    "\n",
    "    curr_idx = 0\n",
    "\n",
    "    while curr_idx < len(test_data):\n",
    "        batch_file_content: List[Dict[str, Any]] = []\n",
    "        curr_samples = test_data[curr_idx:curr_idx + num_samples_per_batch_file]\n",
    "\n",
    "        for sample_num, sample in enumerate(curr_samples):\n",
    "            print(f\"sample: {curr_idx+sample_num}\")\n",
    "            batch_user_messages: List[Dict[str, str]] = []\n",
    "\n",
    "            if few_shot_examples is not None:\n",
    "                batch_user_messages += few_shot_examples\n",
    "\n",
    "            study_example_str = prepare_study_examples(sample['study_examples'])\n",
    "            input_grid_str = sample['queries'][0][0]\n",
    "            \n",
    "            batch_user_messages += [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        { \"type\": \"text\", \"text\": user_prompt + f\"Study examples:{study_example_str}\\n\\n\" + f\"Final input:\\n{input_grid_str}\"},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{plot_study_examples(sample)}\",\n",
    "                                \"detail\": \"high\"\n",
    "                            },\n",
    "                        },\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            batch_file_content.append(\n",
    "                    {\n",
    "                        \"custom_id\": f\"test_sample_{curr_idx+sample_num}\",\n",
    "                        \"method\": \"POST\",\n",
    "                        \"url\": \"/v1/chat/completions\",\n",
    "                        \"body\": {\n",
    "                            \"model\": model,\n",
    "                            \"messages\": batch_user_messages,\n",
    "                            \"max_tokens\": 1000\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "        \n",
    "        if few_shot_examples is None:\n",
    "            file_name = f\"batch_file_samples_{curr_idx}-{min(curr_idx + num_samples_per_batch_file - 1, len(test_data) - 1)}.jsonl\"\n",
    "        else:\n",
    "            file_name = f\"batch_file_few_shots_samples_{curr_idx}-{min(curr_idx + num_samples_per_batch_file - 1, len(test_data) - 1)}.jsonl\"\n",
    "        \n",
    "        save_dicts_as_jsonl(\n",
    "            data=batch_file_content,\n",
    "            filepath=f\"{out_dir}/{file_name}\"\n",
    "        )\n",
    "\n",
    "        curr_idx += num_samples_per_batch_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_batch_files(\n",
    "    test_data=test_data,\n",
    "    user_prompt=user_prompt,\n",
    "    num_samples_per_batch_file=2500,\n",
    "    model=MODEL,\n",
    "    out_dir=OUT_DIR,\n",
    "    few_shot_examples=None\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmlc-GKJ9eXaW-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
