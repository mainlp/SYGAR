{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create OpenAI Batch Files for Few-Shot Abstract Visual Reasoning Task\n",
    "This script creates prompts for the few-shot task. We use `GPT-4o` via the OpenAI API to evaluate the model on the abstract visual reasoning task. We create a batch files that contain chunks of the test set. The input is the same as given to the meta-learning model, with an additional prompt that instructs the model with the respective task. The output should be the predicted output grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Batch File\n",
    "We exploit OpenAI's Batch API to make efficient use of their model and reduce API costs. For this, we first need to create a batch file that contains all the prompts we want to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-2024-08-06\"\n",
    "\n",
    "SEED = 1860\n",
    "DATA_DIR = f\"data/split_seed_{SEED}_only_few_shots\"\n",
    "FILE_NAME = f\"systematicity_seed_{SEED}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Output paths\n",
    "CURR_FILE_PATH = Path.cwd().resolve()\n",
    "OUT_DIR = f\"{MODEL}/batch_files/split_seed_{SEED}_only_few_shots\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"### Task Description:\n",
    "You must solve an abstract visual reasoning task by identifying geometric transformations (e.g., rotation, translation, color changes, etc.) applied to objects within a 10x10 grid.\n",
    "\n",
    "To infer the correct geometric transformation, you are given a series of **3 pairs of input-output examples**. Each example pair consists of:\n",
    "- An **input grid**: a 10x10 list of lists (2d array), where each element is an integer (0-9).\n",
    "- A corresponding **output grid**: a 10x10 list of lists (2d array) that has undergone a transformation based on a specific geometric rule.\n",
    "\n",
    "For the prediction you need to understand the transformations displayed in the provided examples and apply them to the final input grid.\n",
    "\n",
    "#### Your Task:\n",
    "1. **Analyze** the example pairs to infer the transformation rules applied to each input grid.\n",
    "2. **Identify** how these transformations are applied to generate the output grids.\n",
    "3. **Apply** the deduced transformations to the final input grid.\n",
    "4. **Output** the correctly transformed 10x10 grid.\n",
    "\n",
    "### Output Requirements:\n",
    "- **Return only the final output grid.**\n",
    "- Do not include any extra text, explanations, or comments.\n",
    "- Do not generate any code to solve the task.\n",
    "- The output must be formatted exactly as:\n",
    " `output: [[...]]`\n",
    "- The output grid must be a 10x10 list of lists containing only integers between 0 and 9 (inclusive).\n",
    "- Do not include unnecessary line breaks or additional text beyond the specified format.\n",
    "\n",
    "### Input Format:\n",
    "You will receive the following data:\n",
    "1. **Study examples:** A list of 3 few-shot example pairs, formatted as:\n",
    "  `example input 1: [[...]], example output 1: [[...]], ..., example input 3: [[...]], example output 3: [[...]]`\n",
    "2. **Final input:** A single 10x10 list of lists on which you must apply the inferred transformation(s).\n",
    "\n",
    "Your goal is to determine the correct transformation and return the final output grid.\n",
    "\n",
    "### Input:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vmlc.utils.utils import load_jsonl\n",
    "\n",
    "test_data = load_jsonl(\n",
    "    file_path=f\"{DATA_DIR}/test_{FILE_NAME}.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Dict, Optional\n",
    "\n",
    "from vmlc.utils.utils import save_dicts_as_jsonl\n",
    "\n",
    "def prepare_study_examples(study_examples: List[List[List[List[str]]]]) -> str:\n",
    "    study_example_str = \"\"\n",
    "\n",
    "    for idx, input_output_pair in enumerate(study_examples):\n",
    "        assert len(input_output_pair) == 2, f\"Invalid number of input and output grids! {len(input_output_pair)}\"\n",
    "        input_grid = f\"\\nexample input {idx + 1}: {input_output_pair[0]}\"\n",
    "        output_grid = f\"\\nexample output {idx + 1}: {input_output_pair[1]}\"\n",
    "\n",
    "        study_example_str += input_grid + output_grid\n",
    "    \n",
    "    return study_example_str\n",
    "\n",
    "\n",
    "def prepare_batch_files(\n",
    "    test_data: List[Dict[str, Any]],\n",
    "    user_prompt: str,\n",
    "    num_samples_per_batch_file: int,\n",
    "    model: str,\n",
    "    out_dir: str,\n",
    "    few_shot_examples: Optional[List[str]] = None\n",
    ") -> None:\n",
    "\n",
    "    curr_idx = 0\n",
    "\n",
    "    while curr_idx < len(test_data):\n",
    "        batch_file_content: List[Dict[str, Any]] = []\n",
    "        curr_samples = test_data[curr_idx:curr_idx + num_samples_per_batch_file]\n",
    "\n",
    "        for sample_num, sample in enumerate(curr_samples):\n",
    "            batch_user_messages: List[Dict[str, str]] = []\n",
    "\n",
    "            if few_shot_examples is not None:\n",
    "                batch_user_messages += few_shot_examples\n",
    "\n",
    "            study_example_str = prepare_study_examples(sample['study_examples'])\n",
    "            input_grid_str = sample['queries'][0][0]\n",
    "            \n",
    "            batch_user_messages += [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_prompt + f\"Study examples:{study_example_str}\\n\\n\" + f\"Final input:\\n{input_grid_str}\"\n",
    "                }\n",
    "            ]\n",
    "    \n",
    "            if \"o3-mini\" in MODEL or \"o1\" in MODEL:\n",
    "                batch_file_content.append(\n",
    "                    {\n",
    "                        \"custom_id\": f\"test_sample_{curr_idx+sample_num}\",\n",
    "                        \"method\": \"POST\",\n",
    "                        \"url\": \"/v1/chat/completions\",\n",
    "                        \"body\": {\n",
    "                            \"model\": model,\n",
    "                            \"messages\": batch_user_messages,\n",
    "                            \"max_completion_tokens\": 26000,\n",
    "                            \"reasoning_effort\": \"low\",\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                batch_file_content.append(\n",
    "                    {\n",
    "                        \"custom_id\": f\"test_sample_{curr_idx+sample_num}\",\n",
    "                        \"method\": \"POST\",\n",
    "                        \"url\": \"/v1/chat/completions\",\n",
    "                        \"body\": {\n",
    "                            \"model\": model,\n",
    "                            \"messages\": batch_user_messages,\n",
    "                            \"max_tokens\": 1000\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "        \n",
    "        if few_shot_examples is None:\n",
    "            file_name = f\"batch_file_samples_{curr_idx}-{min(curr_idx + num_samples_per_batch_file - 1, len(test_data) - 1)}.jsonl\"\n",
    "        else:\n",
    "            file_name = f\"batch_file_few_shots_samples_{curr_idx}-{min(curr_idx + num_samples_per_batch_file - 1, len(test_data) - 1)}.jsonl\"\n",
    "        \n",
    "        save_dicts_as_jsonl(\n",
    "            data=batch_file_content,\n",
    "            filepath=f\"{out_dir}/{file_name}\"\n",
    "        )\n",
    "\n",
    "        curr_idx += num_samples_per_batch_file      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_batch_files(\n",
    "    test_data=test_data,\n",
    "    user_prompt=user_prompt,\n",
    "    num_samples_per_batch_file=2500,\n",
    "    model=MODEL,\n",
    "    out_dir=OUT_DIR,\n",
    "    few_shot_examples=None\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmlc-DiGlUgMh-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
