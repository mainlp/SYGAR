{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create OpenAI Batch Files for Systematicity Abstract Visual Reasoning Task\n",
    "This script creates prompts related to the systematicity experiment. We use `GPT-4o` via the OpenAI API to evaluate the model on the abstract visual reasoning task. We create a batch files that contain chunks of the test set. The input is the same as given to the meta-learning model, with an additional prompt that instructs the model with the respective task. The output should be the predicted output grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Batch File\n",
    "We exploit OpenAI's Batch API to make efficient use of their model and reduce API costs. For this, we first need to create a batch file that contains all the prompts we want to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-2024-08-06\"\n",
    "\n",
    "SEED = 1860\n",
    "DATA_DIR = f\"data/split_seed_{SEED}\"\n",
    "FILE_NAME = f\"systematicity_seed_{SEED}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Output paths\n",
    "CURR_FILE_PATH = Path.cwd().resolve()\n",
    "OUT_DIR = f\"{MODEL}/batch_files/split_seed_{SEED}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"### Task Description:\n",
    "You must solve an abstract visual reasoning task by identifying geometric transformations (e.g., rotation, translation, color changes, etc.) applied to objects within a 10x10 grid.\n",
    "\n",
    "To infer the correct geometric transformation, you are given a series of **12 pairs of input-output examples**. Each example pair consists of:\n",
    "- An **input grid**: a 10x10 list of lists (2d array), where each element is an integer (0-9).\n",
    "- A corresponding **output grid**: a 10x10 list of lists (2d array) that has undergone a transformation based on a specific geometric rule.\n",
    "\n",
    "The first 6 example pairs demonstrate primitive transformations based on the object's color, shape, or the presence of an additional object.\n",
    "For instance, objects of a certain color within the 10x10 input grid might undergo a translation, while objects of a certain shape (distinct numerical pattern) are being rotated.\n",
    "\n",
    "The latter 6 example pairs involve **composite transformations**, meaning multiple transformations are applied simultaneously.\n",
    "For instance, for objects that have the appropriate color **and** shape, both a translation and rotation are applied simultaneously.\n",
    "\n",
    "For the final prediction you need to understand and further combine the transformations displayed in the provided examples and apply them to the final input grid.\n",
    "\n",
    "#### Your Task:\n",
    "1. **Analyze** the example pairs to infer the transformation rules applied to each input grid.\n",
    "2. **Identify** how these transformations might combine to generate the output grids.\n",
    "3. **Apply** the deduced transformations to the final input grid.\n",
    "4. **Output** the correctly transformed 10x10 grid.\n",
    "\n",
    "### Output Requirements:\n",
    "- **Return only the final output grid.**\n",
    "- Do not include any extra text, explanations, or comments.\n",
    "- The output must be formatted exactly as:\n",
    " `output: [[...]]`\n",
    "- The output grid must be a 10x10 list of lists containing only integers between 0 and 9 (inclusive).\n",
    "- Do not include unnecessary line breaks or additional text beyond the specified format.\n",
    "\n",
    "### Input Format:\n",
    "You will receive the following data:\n",
    "1. **Study examples:** A list of 12 study example pairs, formatted as:\n",
    "  `example input 1: [[...]], example output 1: [[...]], ..., example input 12: [[...]], example output 12: [[...]]`\n",
    "2. **Final input:** A single 10x10 list of lists on which you must apply the inferred transformation(s).\n",
    "\n",
    "Your goal is to determine the correct transformation and return the final output grid.\n",
    "\n",
    "### Input:\n",
    "\"\"\"\n",
    "user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vmlc.utils.utils import load_jsonl\n",
    "\n",
    "test_data = load_jsonl(\n",
    "    file_path=f\"{DATA_DIR}/test_{FILE_NAME}.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Dict, Optional\n",
    "\n",
    "from vmlc.utils.utils import save_dicts_as_jsonl\n",
    "\n",
    "def prepare_study_examples(study_examples: List[List[List[List[str]]]]) -> str:\n",
    "    study_example_str = \"\"\n",
    "\n",
    "    for idx, input_output_pair in enumerate(study_examples):\n",
    "        assert len(input_output_pair) == 2, f\"Invalid number of input and output grids! {len(input_output_pair)}\"\n",
    "        input_grid = f\"\\nexample input {idx + 1}: {input_output_pair[0]}\"\n",
    "        output_grid = f\"\\nexample output {idx + 1}: {input_output_pair[1]}\"\n",
    "\n",
    "        study_example_str += input_grid + output_grid\n",
    "    \n",
    "    return study_example_str\n",
    "\n",
    "\n",
    "def prepare_batch_files(\n",
    "    test_data: List[Dict[str, Any]],\n",
    "    user_prompt: str,\n",
    "    num_samples_per_batch_file: int,\n",
    "    model: str,\n",
    "    out_dir: str,\n",
    "    few_shot_examples: Optional[List[str]] = None\n",
    ") -> None:\n",
    "\n",
    "    curr_idx = 0\n",
    "\n",
    "    while curr_idx < len(test_data):\n",
    "        batch_file_content: List[Dict[str, Any]] = []\n",
    "        curr_samples = test_data[curr_idx:curr_idx + num_samples_per_batch_file]\n",
    "\n",
    "        for sample_num, sample in enumerate(curr_samples):\n",
    "            batch_user_messages: List[Dict[str, str]] = []\n",
    "\n",
    "            if few_shot_examples is not None:\n",
    "                batch_user_messages += few_shot_examples\n",
    "\n",
    "            study_example_str = prepare_study_examples(sample['study_examples'])\n",
    "            input_grid_str = sample['queries'][0][0]\n",
    "            \n",
    "            batch_user_messages += [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_prompt + f\"Study examples:{study_example_str}\\n\\n\" + f\"Final input:\\n{input_grid_str}\"\n",
    "                }\n",
    "            ]\n",
    "    \n",
    "            if \"o3-mini\" in MODEL or \"o1\" in MODEL:\n",
    "                batch_file_content.append(\n",
    "                    {\n",
    "                        \"custom_id\": f\"test_sample_{curr_idx+sample_num}\",\n",
    "                        \"method\": \"POST\",\n",
    "                        \"url\": \"/v1/chat/completions\",\n",
    "                        \"body\": {\n",
    "                            \"model\": model,\n",
    "                            \"messages\": batch_user_messages,\n",
    "                            \"max_completion_tokens\": 26000,\n",
    "                            \"reasoning_effort\": \"low\",\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                batch_file_content.append(\n",
    "                    {\n",
    "                        \"custom_id\": f\"test_sample_{curr_idx+sample_num}\",\n",
    "                        \"method\": \"POST\",\n",
    "                        \"url\": \"/v1/chat/completions\",\n",
    "                        \"body\": {\n",
    "                            \"model\": model,\n",
    "                            \"messages\": batch_user_messages,\n",
    "                            \"max_tokens\": 1000\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "        \n",
    "        if few_shot_examples is None:\n",
    "            file_name = f\"batch_file_samples_{curr_idx}-{min(curr_idx + num_samples_per_batch_file - 1, len(test_data) - 1)}.jsonl\"\n",
    "        else:\n",
    "            file_name = f\"batch_file_few_shots_samples_{curr_idx}-{min(curr_idx + num_samples_per_batch_file - 1, len(test_data) - 1)}.jsonl\"\n",
    "        \n",
    "        save_dicts_as_jsonl(\n",
    "            data=batch_file_content,\n",
    "            filepath=f\"{out_dir}/{file_name}\"\n",
    "        )\n",
    "\n",
    "        curr_idx += num_samples_per_batch_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_batch_files(\n",
    "    test_data=test_data,\n",
    "    user_prompt=user_prompt,\n",
    "    num_samples_per_batch_file=2500,\n",
    "    model=MODEL,\n",
    "    out_dir=OUT_DIR,\n",
    "    few_shot_examples=None\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmlc-DiGlUgMh-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
