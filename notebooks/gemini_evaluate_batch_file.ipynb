{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model on Abstract Visual Reasoning Task\n",
    "We use `Gemini` via the Google GenAI API to evaluate the model on the abstract visual reasoning task. We create a batch files that contain chunks of the test set. The input is the same as given to the meta-learning model, with an additional prompt that instructs the model with the respective task. The output should be the predicted output grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Batch Files\n",
    "The following code evaluates the error types in the batch files. The batch files are stored in the `batch_files` directory. The code reads the batch files, sends the statements to the Gemini model, and evaluates the results. The results are stored in the `gemini` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_INPUT = True\n",
    "ONLY_FEW_SHOTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1860\n",
    "MODEL = \"gemini-2.0-flash-001\"\n",
    "\n",
    "FILE_NAME = f\"systematicity_seed_{SEED}\"\n",
    "BACTHFOLDER = \"image_batch_files\" if IMAGE_INPUT else \"batch_files\"\n",
    "DATA_DIR = f\"gs://mlc_bucket/{BACTHFOLDER}/split_seed_{SEED}\"\n",
    "\n",
    "if ONLY_FEW_SHOTS:\n",
    "    DATA_DIR += \"_only_few_shots\"\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "CURR_FILE_PATH = Path.cwd().resolve()\n",
    "IMG_SPEC = \"with_images\" if IMAGE_INPUT else \"text_only\"\n",
    "FEW_SHOT_SPEC = \"only_few_shots\" if ONLY_FEW_SHOTS else \"vanilla\"\n",
    "OUT_DIR = f\"gs://mlc_bucket/output/{MODEL}/{IMG_SPEC}/{FEW_SHOT_SPEC}\"\n",
    "OUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the project ID key from environment variable\n",
    "PROJECT_ID = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\n",
    "\n",
    "# Check if the project ID key is retrieved successfully\n",
    "if not PROJECT_ID:\n",
    "    raise ValueError(\"Google project ID key not found. Ensure the GOOGLE_CLOUD_PROJECT environment variable is set correctly.\")\n",
    "\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "# set up client\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script\n",
    "Scripts to evaluate the error types in the models' responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Batch File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA = f\"{DATA_DIR}/batch_file_samples_0-2499.jsonl\"\n",
    "BUCKET_URI = \"gs://mlc_bucket/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai.types import CreateBatchJobConfig\n",
    "\n",
    "gcs_batch_job = client.batches.create(\n",
    "    model=MODEL,\n",
    "    src=INPUT_DATA,\n",
    "    config=CreateBatchJobConfig(dest=OUT_DIR),\n",
    ")\n",
    "gcs_batch_job.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_jobs = 4\n",
    "latest_jobs = []\n",
    "for i, job in enumerate(client.batches.list()):\n",
    "    if i+1 > num_jobs:\n",
    "        break\n",
    "    latest_jobs.append(job)\n",
    "    print(job.name, job.create_time, job.state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmlc-DiGlUgMh-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
