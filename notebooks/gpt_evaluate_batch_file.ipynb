{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model on Abstract Visual Reasoning Task\n",
    "We use `GPT-4o` via the OpenAI API to evaluate the model on the abstract visual reasoning task. We create a batch files that contain chunks of the test set. The input is the same as given to the meta-learning model, with an additional prompt that instructs the model with the respective task. The output should be the predicted output grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Batch Files\n",
    "The following code evaluates the error types in the batch files. The batch files are stored in the `batch_files` directory. The code reads the batch files, sends the statements to the GPT-4o model, and evaluates the results. The results are stored in the `gpt-4o` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_INPUT = True\n",
    "ONLY_FEW_SHOTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1860\n",
    "MODEL = \"gpt-4o-2024-08-06\"\n",
    "\n",
    "FILE_NAME = f\"systematicity_seed_{SEED}\"\n",
    "BACTHFOLDER = \"image_batch_files\" if IMAGE_INPUT else \"batch_files\"\n",
    "DATA_DIR = f\"{MODEL}/{BACTHFOLDER}/split_seed_{SEED}\"\n",
    "\n",
    "if ONLY_FEW_SHOTS:\n",
    "    DATA_DIR += \"_only_few_shots\"\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "CURR_FILE_PATH = Path.cwd().resolve()\n",
    "IMG_SPEC = \"with_images\" if IMAGE_INPUT else \"text_only\"\n",
    "FEW_SHOT_SPEC = \"only_few_shots\" if ONLY_FEW_SHOTS else \"vanilla\"\n",
    "OUT_DIR = str(CURR_FILE_PATH.parent / \"experimental_results\" / MODEL / IMG_SPEC / FEW_SHOT_SPEC)\n",
    "OUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the API key from environment variable\n",
    "api_key = os.getenv(\"OPENAI_API_VMLC\")\n",
    "\n",
    "# Check if the API key is retrieved successfully\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found. Ensure the OPENAI_API_KEY environment variable is set correctly.\")\n",
    "\n",
    "# Set the OpenAI API key\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script\n",
    "Scripts to evaluate the error types in the models' responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Status of Batch Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "def get_batch_status(num_jobs: int = 12) -> list[str]:\n",
    "    batches = openai.batches.list(limit=10)\n",
    "    batch_id_list: list[str] = []\n",
    "\n",
    "    for batch in batches:\n",
    "        batch_id = batch.id\n",
    "        status_object = client.batches.retrieve(batch_id)\n",
    "        status = status_object.status\n",
    "        if len(batch_id_list) < num_jobs:\n",
    "            print(f\"id: {batch_id} - status: {status}\")\n",
    "            batch_id_list.append(batch_id)\n",
    "        else:\n",
    "            break\n",
    "    return batch_id_list\n",
    "\n",
    "batch_ids = get_batch_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create batch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def create_batch(\n",
    "    batch_file_path: Path,\n",
    "    description: str\n",
    ") -> None:\n",
    "    batch_input_file = client.files.create(\n",
    "        file=open(batch_file_path, \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "\n",
    "    client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": description\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "\n",
    "in_file_name = \"batch_file_samples_0-2499.jsonl\"\n",
    "batch_file_path = f\"{DATA_DIR}/{in_file_name}\"\n",
    "\n",
    "if ONLY_FEW_SHOTS:\n",
    "    description = \"3 few-shot study examples, 1 input query, \"\n",
    "else:\n",
    "    description = \"12 systematic study examples, 1 input query, \"\n",
    "\n",
    "description += \"with image data.\" if IMAGE_INPUT else \"text only.\"\n",
    "\n",
    "create_batch(\n",
    "    batch_file_path=batch_file_path,\n",
    "    description=description\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "from vmlc.utils.utils import save_dicts_as_jsonl\n",
    "\n",
    "\n",
    "def get_batch_status(num_jobs: int = 12) -> list[str]:\n",
    "    batches = openai.batches.list(limit=10)\n",
    "    batch_id_list: list[str] = []\n",
    "\n",
    "    for batch in batches:\n",
    "        batch_id = batch.id\n",
    "        status_object = client.batches.retrieve(batch_id)\n",
    "        status = status_object.status\n",
    "        if len(batch_id_list) < num_jobs:\n",
    "            print(f\"id: {batch_id} - status: {status}\")\n",
    "            batch_id_list.append(batch_id)\n",
    "        else:\n",
    "            break\n",
    "    return batch_id_list\n",
    "\n",
    "\n",
    "def read_file_content(\n",
    "    client: OpenAI,\n",
    "    file_id: str\n",
    ") -> list[dict]:\n",
    "    http_content = client.files.content(file_id)\n",
    "    jsonl_str_content = http_content.read().decode(\"utf-8\").strip().split(\"\\n\")\n",
    "    jsonl_content = [json.loads(str_content) for str_content in jsonl_str_content if str_content]\n",
    "\n",
    "    return jsonl_content\n",
    "\n",
    "\n",
    "def extract_relevant_content(\n",
    "    in_content: list[dict],\n",
    "    out_content: list[dict]\n",
    ") -> list[dict]:\n",
    "    assert len(in_content) == len(out_content), f\"Length mismatch between input file and output file!\"\n",
    "    relevant_content: list[dict] = []\n",
    "\n",
    "    for (in_row, out_row) in zip(in_content, out_content):\n",
    "        custom_id = out_row[\"custom_id\"]\n",
    "        status_code = out_row[\"response\"][\"status_code\"]\n",
    "        error = out_row[\"error\"]\n",
    "        evaluator_response = out_row[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "        problem_and_response = [in_row[\"body\"][\"messages\"][i][\"content\"] for i in range(len(in_row[\"body\"][\"messages\"]))]\n",
    "\n",
    "        relevant_content.append(\n",
    "            {\n",
    "                \"custom_id\": custom_id,\n",
    "                \"status_code\": status_code,\n",
    "                \"error\": error,\n",
    "                \"evaluator_input\": problem_and_response, \n",
    "                \"evaluator_response\": evaluator_response,\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    return relevant_content\n",
    "\n",
    "\n",
    "def retrieve_batch_response(\n",
    "    client: OpenAI,\n",
    "    batch_id: str\n",
    ") -> None:\n",
    "    batch = client.batches.retrieve(batch_id)\n",
    "    status = batch.status\n",
    "    print(f\"Batch ID: {batch_id} - Status: {status}\")\n",
    "\n",
    "    if status == \"completed\":\n",
    "        print(f\"Saving batch {batch_id}...\")\n",
    "        file_name = f\"batch_id_{batch_id}.jsonl\"\n",
    "\n",
    "        in_content = read_file_content(\n",
    "            client=client,\n",
    "            file_id=batch.input_file_id\n",
    "        )\n",
    "\n",
    "        out_content = read_file_content(\n",
    "            client=client,\n",
    "            file_id=batch.output_file_id\n",
    "        )\n",
    "        # save entire output\n",
    "        save_dicts_as_jsonl(data=out_content, filepath=f\"{OUT_DIR}/openai_output/{file_name}\")\n",
    "\n",
    "        # save relevant parts\n",
    "        relevant_content = extract_relevant_content(\n",
    "            in_content=in_content,\n",
    "            out_content=out_content\n",
    "        )\n",
    "        save_dicts_as_jsonl(data=relevant_content, filepath=f\"{OUT_DIR}/{file_name}\")\n",
    "    else:\n",
    "        print(f\"Batch {batch_id} not completed yet. Please try again later.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_batch_ids = get_batch_status(num_jobs=3)\n",
    "last_batch_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "for batch_id in last_batch_ids:\n",
    "    try:\n",
    "        retrieve_batch_response(\n",
    "            client=client,\n",
    "            batch_id=batch_id\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmlc-DiGlUgMh-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
