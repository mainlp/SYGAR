{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Google Gemini Batch Files with Images for Few-Shot Abstract Visual Reasoning Task\n",
    "This script creates prompts for the few-shot task. We use Gemini Flash via the Google GenAI API to evaluate the model on the abstract visual reasoning task. We create a batch files that contain chunks of the test set. The input is the same as given to the meta-learning model, with an additional prompt that instructs the model with the respective task, and an image displaying the puzzle. The output should be the predicted output grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Batch File\n",
    "We exploit Google's Batch API to make efficient use of their model and reduce API costs. For this, we first need to create a batch file that contains all the prompts we want to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONLY_FEW_SHOTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gemini-2.0-flash-001\"\n",
    "\n",
    "SEED = 1860\n",
    "DATA_FOLDER = f\"split_seed_{SEED}_only_few_shots\" if ONLY_FEW_SHOTS else f\"split_seed_{SEED}\"\n",
    "DATA_DIR = f\"data/{DATA_FOLDER}\"\n",
    "FILE_NAME = f\"systematicity_seed_{SEED}\"\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Output paths\n",
    "CURR_FILE_PATH = Path.cwd().resolve()\n",
    "OUT_DIR = f\"{MODEL}/image_batch_files/split_seed_{SEED}\"\n",
    "\n",
    "if ONLY_FEW_SHOTS:\n",
    "    OUT_DIR += \"_only_few_shots\"\n",
    "OUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DATA_FOLDER = f\"split_seed_{SEED}_only_few_shots\" if ONLY_FEW_SHOTS else f\"split_seed_{SEED}\"\n",
    "IMG_DIR = f\"gs://mlc_bucket/image_batch_files/{IMG_DATA_FOLDER}/imgs\"\n",
    "IMG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the project ID key from environment variable\n",
    "PROJECT_ID = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\n",
    "\n",
    "# Check if the project ID key is retrieved successfully\n",
    "if not PROJECT_ID:\n",
    "    raise ValueError(\"Google project ID key not found. Ensure the GOOGLE_CLOUD_PROJECT environment variable is set correctly.\")\n",
    "\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "# set up client\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ONLY_FEW_SHOTS:\n",
    "    user_prompt = \"\"\"### Task Description:\n",
    "You must solve an abstract visual reasoning task by identifying geometric transformations (e.g., rotation, translation, color changes, etc.) applied to objects within a 10x10 grid.\n",
    "\n",
    "To infer the correct geometric transformation, you are given a series of **3 pairs of input-output examples**. Each example pair consists of:\n",
    "- An **input grid**: a 10x10 list of lists (2d array), where each element is an integer (0-9).\n",
    "- A corresponding **output grid**: a 10x10 list of lists (2d array) that has undergone a transformation based on a specific geometric rule.\n",
    "\n",
    "For the prediction you need to understand the transformations displayed in the provided examples and apply them to the final input grid.\n",
    "\n",
    "#### Your Task:\n",
    "1. **Analyze** the example pairs to infer the transformation rules applied to each input grid.\n",
    "2. **Identify** how these transformations are applied to generate the output grids.\n",
    "3. **Apply** the deduced transformations to the final input grid.\n",
    "4. **Output** the correctly transformed 10x10 grid.\n",
    "\n",
    "### Output Requirements:\n",
    "- **Return only the final output grid.**\n",
    "- Do not include any extra text, explanations, or comments.\n",
    "- Do not generate any code to solve the task.\n",
    "- The output must be formatted exactly as:\n",
    " `output: [[...]]`\n",
    "- The output grid must be a 10x10 list of lists containing only integers between 0 and 9 (inclusive).\n",
    "- Do not include unnecessary line breaks or additional text beyond the specified format.\n",
    "\n",
    "### Input Format:\n",
    "You will receive the following data:\n",
    "1. **Study examples:** A list of 3 few-shot example pairs, formatted as:\n",
    "  `example input 1: [[...]], example output 1: [[...]], ..., example input 3: [[...]], example output 3: [[...]]`\n",
    "2. **Final input:** A single 10x10 list of lists on which you must apply the inferred transformation(s).\n",
    "3. **Image input:** Addtionally, you receive an image that visualizes the 3 few-shot example pairs and the final input query.\n",
    "\n",
    "Your goal is to determine the correct transformation and return the final output grid.\n",
    "\n",
    "### Input:\n",
    "\"\"\"\n",
    "else:\n",
    "    user_prompt = \"\"\"### Task Description:\n",
    "You must solve an abstract visual reasoning task by identifying geometric transformations (e.g., rotation, translation, color changes, etc.) applied to objects within a 10x10 grid.\n",
    "\n",
    "To infer the correct geometric transformation, you are given a series of **12 pairs of input-output examples**. Each example pair consists of:\n",
    "- An **input grid**: a 10x10 list of lists (2d array), where each element is an integer (0-9).\n",
    "- A corresponding **output grid**: a 10x10 list of lists (2d array) that has undergone a transformation based on a specific geometric rule.\n",
    "\n",
    "The first 6 example pairs demonstrate primitive transformations based on the object's color, shape, or the presence of an additional object.\n",
    "For instance, objects of a certain color within the 10x10 input grid might undergo a translation, while objects of a certain shape (distinct numerical pattern) are being rotated.\n",
    "\n",
    "The latter 6 example pairs involve **composite transformations**, meaning multiple transformations are applied simultaneously.\n",
    "For instance, for objects that have the appropriate color **and** shape, both a translation and rotation are applied simultaneously.\n",
    "\n",
    "For the final prediction you need to understand and further combine the transformations displayed in the provided examples and apply them to the final input grid.\n",
    "\n",
    "#### Your Task:\n",
    "1. **Analyze** the example pairs to infer the transformation rules applied to each input grid.\n",
    "2. **Identify** how these transformations might combine to generate the output grids.\n",
    "3. **Apply** the deduced transformations to the final input grid.\n",
    "4. **Output** the correctly transformed 10x10 grid.\n",
    "\n",
    "### Output Requirements:\n",
    "- **Return only the final output grid.**\n",
    "- Do not include any extra text, explanations, or comments.\n",
    "- The output must be formatted exactly as:\n",
    " `output: [[...]]`\n",
    "- The output grid must be a 10x10 list of lists containing only integers between 0 and 9 (inclusive).\n",
    "- Do not include unnecessary line breaks or additional text beyond the specified format.\n",
    "- **Do not show any python code to solve the task.**\n",
    "\n",
    "### Input Format:\n",
    "You will receive the following data:\n",
    "1. **Study examples:** A list of 12 study example pairs, formatted as:\n",
    "  `example input 1: [[...]], example output 1: [[...]], ..., example input 12: [[...]], example output 12: [[...]]`\n",
    "2. **Final input:** A single 10x10 list of lists on which you must apply the inferred transformation(s).\n",
    "3. **Image input:** Addtionally, you receive an image that visualizes the 12 study example pairs and the final input query.\n",
    "\n",
    "Your goal is to determine the correct transformation and return the final output grid.\n",
    "\n",
    "### Input:\n",
    "\"\"\"\n",
    "user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vmlc.utils.utils import load_jsonl\n",
    "\n",
    "test_data = load_jsonl(\n",
    "    file_path=f\"{DATA_DIR}/test_{FILE_NAME}.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "def get_custom_cmap() -> mcolors.ListedColormap:\n",
    "    \"\"\"\n",
    "    Returns a ListedColormap using a specified color order.\n",
    "\n",
    "    Returns:\n",
    "        mcolors.ListedColormap: The custom colormap.\n",
    "    \"\"\"\n",
    "    colors = [\n",
    "        \"black\",   # Background (value 0)\n",
    "        \"red\",     # value 1\n",
    "        \"orange\",  # value 2\n",
    "        \"yellow\",  # value 3\n",
    "        \"green\",   # value 4\n",
    "        \"blue\",    # value 5\n",
    "        \"purple\",  # value 6\n",
    "        \"pink\",    # value 7\n",
    "        \"cyan\",    # value 8\n",
    "        \"grey\",    # value 9\n",
    "        \"white\"    # Extra if needed\n",
    "    ]\n",
    "    return mcolors.ListedColormap(colors)\n",
    "\n",
    "def plot_grid(ax: plt.Axes, grid: Any, title: str, cmap: mcolors.Colormap,\n",
    "              vmin: int = 0, vmax: int = 10) -> None:\n",
    "    \"\"\"\n",
    "    Plots a grid on the given axes with a title.\n",
    "\n",
    "    Args:\n",
    "        ax (plt.Axes): Axes on which to plot.\n",
    "        grid (Any): Grid data (convertible to a NumPy array).\n",
    "        title (str): Title for the subplot.\n",
    "        cmap (mcolors.Colormap): Colormap to use.\n",
    "        vmin (int, optional): Minimum data value. Defaults to 0.\n",
    "        vmax (int, optional): Maximum data value. Defaults to 10.\n",
    "    \"\"\"\n",
    "    grid_array = np.array(grid)\n",
    "    rows, cols = grid_array.shape\n",
    "    ax.imshow(grid_array, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(title, fontsize=9)\n",
    "    ax.set_xticks(np.arange(cols + 1) - 0.5, minor=True)\n",
    "    ax.set_yticks(np.arange(rows + 1) - 0.5, minor=True)\n",
    "    ax.grid(True, which=\"minor\", color=\"white\", linewidth=0.5)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "def add_arrow(ax: plt.Axes) -> None:\n",
    "    \"\"\"\n",
    "    Adds an arrow annotation to the axes and hides the axis.\n",
    "\n",
    "    Args:\n",
    "        ax (plt.Axes): Axes on which to add the arrow.\n",
    "    \"\"\"\n",
    "    ax.annotate(\n",
    "        \"\",\n",
    "        xy=(1.4, 0.5),\n",
    "        xytext=(-0.8, 0.5),\n",
    "        arrowprops=dict(arrowstyle=\"->\", lw=1),\n",
    "        xycoords=\"axes fraction\",\n",
    "        textcoords=\"axes fraction\"\n",
    "    )\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "def extract_grid_pairs(study_examples: List[Any]) -> List[Tuple[Any, Any]]:\n",
    "    \"\"\"\n",
    "    Extracts input/output grid pairs from the nested 'study_examples' structure.\n",
    "    \n",
    "    Assumes each study example is nested as: example[0] is a list containing\n",
    "    at least two grids (input and output).\n",
    "\n",
    "    Args:\n",
    "        study_examples (List[Any]): The nested study_examples data.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[Any, Any]]: A list of (input_grid, output_grid) pairs.\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    for input_output_pair in study_examples:\n",
    "        pairs.append((input_output_pair[0], input_output_pair[1]))\n",
    "    return pairs\n",
    "\n",
    "def extract_query_input(queries: List[Any]) -> Any:\n",
    "    \"\"\"\n",
    "    Extracts the input grid for the query from the nested 'queries' structure.\n",
    "    \n",
    "    Assumes queries are nested as: queries[0][0][0] is the query input grid.\n",
    "\n",
    "    Args:\n",
    "        queries (List[Any]): The nested queries data.\n",
    "\n",
    "    Returns:\n",
    "        Any: The query input grid.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the query grid is not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return queries[0][0]\n",
    "    except (IndexError, TypeError):\n",
    "        raise ValueError(\"Query input grid not found in the provided data.\")\n",
    "\n",
    "def plot_study_examples(test_episode: Dict[str, Any], file_path: Optional[str] = None, verbose: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    Plots a series of input/output grid pairs from study_examples and a query input\n",
    "    from queries, then saves them to disk.\n",
    "\n",
    "    Args:\n",
    "        test_episode (Dict[str, Any]): Data containing keys 'study_examples' and 'queries'.\n",
    "        file_path (Optional(str), None): The file path to save the image. Defaults to None.\n",
    "        verbose (int): Verbosity level. Defaults to 0.\n",
    "    \"\"\"\n",
    "    cmap = get_custom_cmap()\n",
    "\n",
    "    # Extract grid pairs from the study_examples field\n",
    "    study_examples = test_episode.get(\"study_examples\", [])\n",
    "    grids = extract_grid_pairs(study_examples)\n",
    "\n",
    "    # Extract the query input grid from queries\n",
    "    queries = test_episode.get(\"queries\", [])\n",
    "    query_input = extract_query_input(queries)\n",
    "    \n",
    "    if ONLY_FEW_SHOTS:\n",
    "        num_examples = len(grids)\n",
    "\n",
    "        # Create figure: one row per grid pair plus one extra row for the query; 3 columns layout\n",
    "        fig, axes = plt.subplots(num_examples + 1, 3,\n",
    "                                figsize=(7.68, 2 * (num_examples + 2)),\n",
    "                                gridspec_kw={'width_ratios': [1, 0.1, 1]})\n",
    "        fig.suptitle(\"Study Examples\", fontsize=12, fontweight=\"bold\", x=0.02, ha=\"left\", y=0.82)\n",
    "        plt.subplots_adjust(top=0.78, hspace=0.3)\n",
    "\n",
    "        # Plot each study example (input/output pair)\n",
    "        for i in range(num_examples):\n",
    "            plot_grid(axes[i, 0], grids[i][0], f\"Example input {i+1}:\", cmap)\n",
    "            add_arrow(axes[i, 1])\n",
    "            plot_grid(axes[i, 2], grids[i][1], f\"Example output {i+1}:\", cmap)\n",
    "\n",
    "        # Plot query input on the last row (only the input grid)\n",
    "        query_ax = axes[num_examples, 0]\n",
    "        pos = query_ax.get_position()\n",
    "        new_y0 = pos.y0 - 0.01\n",
    "        new_y1 = pos.y1 - 0.01\n",
    "        query_ax.set_position([pos.x0, new_y0, pos.width, new_y1 - new_y0])\n",
    "        plt.text(0, new_y1 + 0.01, \"Query\", fontsize=12, fontweight=\"bold\",\n",
    "                ha=\"left\", transform=fig.transFigure)\n",
    "        plot_grid(query_ax, query_input, \"Final input:\", cmap)\n",
    "        add_arrow(axes[num_examples, 1])\n",
    "        axes[num_examples, 2].axis(\"off\")\n",
    "\n",
    "    else:\n",
    "        num_examples = len(grids) // 2\n",
    "\n",
    "        # Create figure: one row per grid pair plus one extra row for the query; 3 columns layout\n",
    "        fig, axes = plt.subplots(num_examples + 1, 7,\n",
    "                                figsize=(7.68, 2 * (num_examples + 2)),\n",
    "                                gridspec_kw={'width_ratios': [1, 0.1, 1, 1, 1, 0.1, 1]})\n",
    "        fig.suptitle(\"Study Examples\", fontsize=12, fontweight=\"bold\", x=0.02, ha=\"left\", y=0.82)\n",
    "        plt.subplots_adjust(top=0.78, hspace=0.15)\n",
    "\n",
    "        # Plot each study example (input/output pair)\n",
    "        for i in range(num_examples):\n",
    "            plot_grid(axes[i, 0], grids[i][0], f\"Example input {i+1}:\", cmap)\n",
    "            add_arrow(axes[i, 1])\n",
    "            plot_grid(axes[i, 2], grids[i][1], f\"Example output {i+1}:\", cmap)\n",
    "            axes[i, 3].axis(\"off\")\n",
    "        \n",
    "        for i in range(num_examples):\n",
    "            plot_grid(axes[i, 4], grids[num_examples+i][0], f\"Example input {num_examples+i+1}:\", cmap)\n",
    "            add_arrow(axes[i, 5])\n",
    "            plot_grid(axes[i, 6], grids[num_examples+i][1], f\"Example output {num_examples+i+1}:\", cmap)\n",
    "\n",
    "        # Plot query input on the last row (only the input grid)\n",
    "        query_ax = axes[num_examples, 0]\n",
    "        pos = query_ax.get_position()\n",
    "        new_y0 = pos.y0 - 0.01\n",
    "        new_y1 = pos.y1 - 0.01\n",
    "        query_ax.set_position([pos.x0, new_y0, pos.width, new_y1 - new_y0])\n",
    "        plt.text(0, new_y1 + 0.01, \"Query\", fontsize=12, fontweight=\"bold\",\n",
    "                ha=\"left\", transform=fig.transFigure)\n",
    "        plot_grid(query_ax, query_input, \"Final input:\", cmap)\n",
    "        add_arrow(axes[num_examples, 1])\n",
    "        axes[num_examples, 1].axis(\"off\")\n",
    "        axes[num_examples, 2].axis(\"off\")\n",
    "        axes[num_examples, 3].axis(\"off\")\n",
    "        axes[num_examples, 4].axis(\"off\")\n",
    "        axes[num_examples, 5].axis(\"off\")\n",
    "        axes[num_examples, 6].axis(\"off\")\n",
    "\n",
    "    # Optional: print image size info\n",
    "    fig_width, fig_height = fig.get_size_inches()\n",
    "    dpi = fig.dpi\n",
    "\n",
    "    if verbose > 0:\n",
    "        print(f\"Image size: {int(fig_width * dpi)}x{int(fig_height * dpi)} pixels\")\n",
    "        plt.show()\n",
    "\n",
    "    if file_path is not None:\n",
    "        parent_dir = os.path.dirname(file_path)\n",
    "        os.makedirs(parent_dir, exist_ok=True)\n",
    "        fig.savefig(file_path)\n",
    "\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_example = plot_study_examples(test_data[0], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Dict, Optional\n",
    "\n",
    "from vmlc.utils.utils import save_dicts_as_jsonl\n",
    "\n",
    "def prepare_study_examples(study_examples: List[List[List[List[str]]]]) -> str:\n",
    "    study_example_str = \"\"\n",
    "\n",
    "    for idx, input_output_pair in enumerate(study_examples):\n",
    "        assert len(input_output_pair) == 2, f\"Invalid number of input and output grids! {len(input_output_pair)}\"\n",
    "        input_grid = f\"\\nexample input {idx + 1}: {input_output_pair[0]}\"\n",
    "        output_grid = f\"\\nexample output {idx + 1}: {input_output_pair[1]}\"\n",
    "\n",
    "        study_example_str += input_grid + output_grid\n",
    "    \n",
    "    return study_example_str\n",
    "\n",
    "def prepare_batch_files(\n",
    "    test_data: List[Dict[str, Any]],\n",
    "    user_prompt: str,\n",
    "    num_samples_per_batch_file: int,\n",
    "    out_dir: str,\n",
    "    few_shot_examples: Optional[List[str]] = None\n",
    ") -> None:\n",
    "\n",
    "    curr_idx = 0\n",
    "\n",
    "    while curr_idx < len(test_data):\n",
    "        batch_file_content: List[Dict[str, Any]] = []\n",
    "        curr_samples = test_data[curr_idx:curr_idx + num_samples_per_batch_file]\n",
    "\n",
    "        for sample_num, sample in enumerate(curr_samples):\n",
    "            batch_user_messages: List[Dict[str, str]] = []\n",
    "\n",
    "            if few_shot_examples is not None:\n",
    "                batch_user_messages += few_shot_examples\n",
    "\n",
    "            study_example_str = prepare_study_examples(sample['study_examples'])\n",
    "            input_grid_str = sample['queries'][0][0]\n",
    "\n",
    "            # save image\n",
    "            plot_study_examples(\n",
    "                test_episode=sample,\n",
    "                file_path=f\"{OUT_DIR}/imgs/test_sample_{curr_idx+sample_num}.jpeg\"\n",
    "            )\n",
    "            \n",
    "            batch_user_messages += [\n",
    "                {   \n",
    "                    \"role\": \"user\",\n",
    "                    \"parts\": [\n",
    "                        {\"text\": user_prompt + f\"Study examples:{study_example_str}\\n\\n\" + f\"Final input:\\n{input_grid_str}\"},\n",
    "                        {\"fileData\": {\"fileUri\": f\"{IMG_DIR}/test_sample_{curr_idx+sample_num}.jpeg\", \"mimeType\": \"image/jpeg\"}}\n",
    "                    ],\n",
    "                }\n",
    "            ]\n",
    "    \n",
    "            batch_file_content.append(\n",
    "                {   \n",
    "                    \"request\": {\n",
    "                        \"contents\": batch_user_messages,\n",
    "                        \"generationConfig\": {\"max_output_tokens\": 1000},\n",
    "                        \"labels\": {\"custom_id\": f\"test_sample_{curr_idx+sample_num}\"}\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        if few_shot_examples is None:\n",
    "            file_name = f\"batch_file_samples_{curr_idx}-{min(curr_idx + num_samples_per_batch_file - 1, len(test_data) - 1)}.jsonl\"\n",
    "        else:\n",
    "            file_name = f\"batch_file_few_shots_samples_{curr_idx}-{min(curr_idx + num_samples_per_batch_file - 1, len(test_data) - 1)}.jsonl\"\n",
    "        \n",
    "        save_dicts_as_jsonl(\n",
    "            data=batch_file_content,\n",
    "            filepath=f\"{out_dir}/{file_name}\"\n",
    "        )\n",
    "\n",
    "        curr_idx += num_samples_per_batch_file      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_batch_files(\n",
    "    test_data=test_data,\n",
    "    user_prompt=user_prompt,\n",
    "    num_samples_per_batch_file=2500,\n",
    "    out_dir=OUT_DIR,\n",
    "    few_shot_examples=None\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmlc-DiGlUgMh-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
